# -*- coding: utf-8 -*-
"""time series bitcoin  (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tCWyWp8meBQh7yHuO3bjvBz0DM4OJCgB

# IMPORT ALL LIBRARIES NEEDED
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd #### Library for working with large datsets
import numpy as np #### Library for performing numerical calculations
import matplotlib.pyplot as plt #### Baasic Library for plotting graphs
# %matplotlib inline 
plt.rcParams['figure.figsize'] = (12, 12) ### Setting the size of the Plots
import datetime as dt
from math import radians, cos, sin, asin, sqrt
from sklearn.preprocessing import MinMaxScaler
#from prophet import Prophet
import warnings
warnings.filterwarnings('ignore')
import seaborn as sns
from statsmodels.tsa.api import ExponentialSmoothing,SimpleExpSmoothing, Holt
from pylab import rcParams
rcParams['figure.figsize']=20,5

"""# LOAD THE DATA"""

ds = pd.read_csv('/content/BTC-USD Training Data - 1st Jan 2016 to 1st Jan 2022.csv')

"""# Exploratory Data Analysis"""

ds.head()

ds.shape[0]

ds.info()

ds.describe()

ds.columns

ds = ds[['Date','Close']]

ds

ds.columns = ['ds','y']

ds.head()

"""# Checking rows with missing values"""

ds.isnull().sum()

"""# Visualize """

import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.api import ExponentialSmoothing,SimpleExpSmoothing, Holt
from pylab import rcParams
rcParams['figure.figsize']=20,5

plt.grid(True)
plt.xlabel('Date',size=15)
plt.ylabel('Closing Price',size=15)
plt.plot(ds['y'],label='y')
plt.legend(loc='best')
plt.show()

"""# Stationarity in Time Series"""

#rolling average transformation with window 20
rollingseries=ds.rolling(window=100)
rollingmean=rollingseries.mean()
rollingstd=rollingseries.std()
rollingmean['y'].head(30)
rollingstd['y'].head(30)

plt.plot(ds['y'],color='green',label='Original')
plt.plot(rollingmean['y'],color='blue',label='Rolling Mean')
plt.plot(rollingstd['y'],color='red',label='Rolling STD')
plt.legend(loc='best')
plt.title('Rolling Mean and Stardard Deviation')
plt.show(block=False)

"""As the rolling mean and rolling standard deviation are not constant over time, we can conclude that the data is not stationary. """

data=ds['y'][:50]
fit1=SimpleExpSmoothing(data).fit(smoothing_level=0.2)
fit2=SimpleExpSmoothing(data).fit(smoothing_level=0.8)

plt.figure(figsize=(18,8))
plt.plot(ds['y'][:50],marker='.',color='black')
plt.plot(fit1.fittedvalues,marker='.',color='blue')
plt.plot(fit2.fittedvalues,marker='.',color='red')

fit1=Holt(data).fit()
fit2=Holt(data,exponential=True).fit()

plt.plot(data,marker='.',color='black')
plt.xticks(rotation=30)
plt.plot(fit1.fittedvalues,marker='*',color='blue')
plt.plot(fit2.fittedvalues,marker='_',color='red')

"""Exponential plot(red) is exactly on the Linear Plot(Blue), hence we can say that the data has a linear trend, not exponential trend."""

from statsmodels.tsa.seasonal import seasonal_decompose
from dateutil.parser import parse
import pandas as pd

ds.head()

"""# ADFULLER TEST FOR STATIONARITY"""

from statsmodels.tsa.stattools import adfuller

#ADF Test - nul hypothesis - non-stationary - if p-value <5% reject null hypothesis
adfuller_result=adfuller(ds.y.values,autolag='AIC')
# adfuller_result

print(f'ADF Statistic: {adfuller_result[0]}')

print(f'P-value: {adfuller_result[1]}')

for key,value in adfuller_result[4].items():
    print('Critical Values:')
    print(f'  {key}, {value}')

"""We can see the P-Value is not <5%, hence we can say that the time series is non-stationary. Due to which we cannot use this time series data for machine learning, without making it stationary.

# Auto regression using ACF and PACF
"""

import matplotlib
matplotlib.rc('xtick',labelsize=30)
matplotlib.rc('ytick',labelsize=30)
###########################################
import seaborn as sns
sns.set(style='whitegrid',color_codes=True)
from statsmodels.tsa.stattools import acf,pacf

#Calling AutoCorrelationFunction with a lag of 200
y=ds['y']
ACF_lag=acf(ds['y'],nlags=800)
###########################################################
plt.figure(figsize=(16,7))
plt.plot(ACF_lag,marker='+')
plt.axhline(y=0,linestyle='--',color='gray')
plt.axhline(y=-1.96/np.sqrt(len(y)),linestyle='--',color='gray')
plt.axhline(y=1.96/np.sqrt(len(y)),linestyle='--',color='gray')
plt.title('Auto Correlation')
plt.xlabel('#lags')
plt.ylabel('correlation')
plt.tight_layout()

"""From the above graph we can see that there is a descent amount of correlation till 600-650 lags.That means the time series is related to previous 650 observations or this time series can be regressed on previous 650 observations.But, if we consider the previous 650 observations, there will be multicolinearaity problem. Because,at time T, if the time series can be explained by T-1, at time T-1 also, the time series can be explained by T-2.

So,we dont want to have a very large no. of lags to be considered, we want to limit this lags, to avoid multicolinearity.

That can be addressed by PACF Chart.
"""

PACF_lag=pacf(y,nlags=30,method='ols')

plt.figure(figsize=(16,7))
plt.plot(PACF_lag,marker='+')
plt.axhline(y=0,linestyle='--',color='gray')
plt.axhline(y=-1.96/np.sqrt(len(y)),linestyle='--',color='gray')
plt.axhline(y=1.96/np.sqrt(len(y)),linestyle='--',color='gray')
plt.title('Partial Autocorrelation')
plt.xlabel('#lags')
plt.ylabel('correlation')
plt.tight_layout()

"""PACF chart shows the actual lags which impacts the time series after removing the noise.

So, from the chart we can see there is a significant amount of correlation upto value 2-2.3, hence our auto regression model should be of window 2.3, i.e. take the lag of the time series upto 2.3 lags and use the time series to predict the next value

# fbprophet
"""

!pip install Prophet

from prophet import Prophet

model = Prophet()

len(ds)

model.fit(ds)

future = model.make_future_dataframe(periods=24,freq='B')

future.tail()

prediction = model.predict(future)

prediction

prediction.tail()

predicted_output = prediction[['ds','yhat_lower', 'yhat_upper','yhat']]

predicted_output

ds

predicted_output

len(predicted_output)

model.plot(predicted_output);

plt.figure(figsize=(16,10))
ds['y'].plot()
prediction['yhat'].plot()
plt.legend()

test_ds = pd.read_csv('/content/BTC-USD Out of Time Testing 1st Jan 2022 to 4th Feb 2022.csv')

test_ds

test_ds.isna().sum()

test_ds = test_ds[['Date','Close']]

test_ds

test_ds['Date'] = pd.to_datetime(test_ds['Date'])

test_ds

predicted_output

comparing_set = predicted_output

len(comparing_set)

comparing_set.drop(labels=1498,axis=0,inplace=True)

len(test_ds)

comparing_set

comparing_set.columns

cm = comparing_set[['ds','yhat']]

cm

#Evaluation Process 
from sklearn.metrics import mean_squared_error
from math import sqrt

print(sqrt(mean_squared_error(cm['yhat'],test_ds['Close'])))